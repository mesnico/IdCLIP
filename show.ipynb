{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "\n",
    "# %matplotlib inline\n",
    "\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_one(run, csv_folder, test_config='general'):\n",
    "    #if run.name == 'baseline':\n",
    "    parameters = {p.split('=')[0]: p.split('=')[1] for p in run.as_posix().split('/') if \"=\" in p}\n",
    "    # else:\n",
    "    #     with open(run / 'config.json', 'r') as f:\n",
    "    #         cfg = json.load(f)\n",
    "            \n",
    "    #     run_dir = cfg[\"run_dir\"]\n",
    "    #     parameters = {p.split('=')[0]: p.split('=')[1] for p in run_dir.split('/') if \"=\" in p}\n",
    "\n",
    "    data = []\n",
    "    for yamlf in (run / 'inference' / csv_folder).rglob('*.csv'):\n",
    "        test_config_name = yamlf.parent.stem\n",
    "        if test_config not in yamlf.parent.stem:\n",
    "            continue\n",
    "        df = pd.read_csv(yamlf)\n",
    "        # keep only the last line. This is because until this commit, we were appending the logs and not overriding them, so the last line is the one we want\n",
    "        df = df.tail(1)\n",
    "        df['tok_position_inference'] = 'beginning' if 'tok_beginning' in test_config_name else 'in_place' if 'tok_in_place' in test_config_name else None\n",
    "        df['inference_config'] = test_config_name.split('retrieval_')[-1] if 'retrieval_' in test_config_name else None\n",
    "        if run.name == 'baseline':\n",
    "            df['model'] = 'clip_original'\n",
    "        data.append(df)\n",
    "    \n",
    "    data = pd.concat(data)\n",
    "    # data.columns.names = ['type', 'metric']\n",
    "    # data.sort_values(by=['type', 'metric'], axis=1, inplace=True)\n",
    "    data.drop(columns=['epoch', 'step'], inplace=True)\n",
    "    \n",
    "    if data.empty:\n",
    "        print(f'Pred folder is empty: {csv_folder}')\n",
    "    \n",
    "    for k, v in parameters.items():\n",
    "        data[k] = v\n",
    "    \n",
    "    return data\n",
    "\n",
    "def collect_all(root, csv_folder, test_config='general'):\n",
    "    root = Path(root)\n",
    "    metrics = [collect_one(csvf.parents[1], csvf.name, test_config=test_config) for csvf in list(root.rglob(csv_folder))]\n",
    "    metrics = pd.concat(metrics, ignore_index=True)\n",
    "    return metrics\n",
    "\n",
    "default_fields_dict = {\n",
    "    'r1': lambda x: u\"{:.1f}\".format(x),\n",
    "    'r5': lambda x: u\"{:.1f}\".format(x),\n",
    "    'r10': lambda x: u\"{:.1f}\".format(x),\n",
    "    'meanr': lambda x: u\"{:.1f}\".format(x),\n",
    "    'medr': lambda x: int(x),\n",
    "    'spice': lambda x: u\"{:.3f}\".format(x),\n",
    "    'spacy': lambda x: u\"{:.3f}\".format(x),\n",
    "}\n",
    "def render_to_latex(metrics, rename_func=default_fields_dict, **latex_kwargs):\n",
    "    m = metrics.copy()\n",
    "    # renaming\n",
    "    for col, lambda_fn in rename_func.items():\n",
    "        m[col] = m[col].apply(lambda_fn)\n",
    "    # m = m.applymap(lambda x: u\"{:.2f}\".format(x))\n",
    "    ltex = m.style.to_latex(\n",
    "        **latex_kwargs\n",
    "    )\n",
    "    return ltex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics for each detected run\n",
    "\n",
    "def summarize_metrics(\n",
    "        metrics, \n",
    "        dataset=None, \n",
    "        model=None,\n",
    "        translator=None,\n",
    "        tok_position=None, \n",
    "        training_setup=None, \n",
    "        inference_config=None,\n",
    "        loss=None, \n",
    "        learning_rate=None, \n",
    "        finetuning=None, \n",
    "        drop_i2t=True,\n",
    "        decimal_places=3):\n",
    "    \n",
    "    if dataset is not None:\n",
    "        metrics = metrics[(metrics['data'] == dataset)]\n",
    "        metrics.drop(columns=\"data\", inplace=True)\n",
    "\n",
    "    # TODO: as of now, there is only one split seed.\n",
    "    # In the future, we would have to average among different splits\n",
    "    # metrics.drop(columns=\"split_seed\", inplace=True)\n",
    "\n",
    "    id_vars = ['data', 'model', 'translator', 'tok_position', 'training-setup', 'loss', 'lr', 'finetuning', 'inference_config']\n",
    "\n",
    "    if translator is not None:\n",
    "        metrics = metrics[metrics['translator'].isin(translator)]\n",
    "        if len(translator) == 1:\n",
    "            metrics.drop(columns=\"translator\", inplace=True)\n",
    "            id_vars.remove('translator')\n",
    "    if model is not None:\n",
    "        metrics = metrics[metrics['model'].isin(model)]\n",
    "        if len(model) == 1:\n",
    "            metrics.drop(columns=\"model\", inplace=True)\n",
    "            id_vars.remove('model')\n",
    "    if learning_rate is not None:\n",
    "        metrics = metrics[metrics['lr'].isin(learning_rate)]\n",
    "        if len(learning_rate) == 1:\n",
    "            metrics.drop(columns=\"lr\", inplace=True)\n",
    "            id_vars.remove('lr')\n",
    "    if finetuning is not None:\n",
    "        metrics = metrics[metrics['finetuning'].isin(finetuning)]\n",
    "        if len(finetuning) == 1:\n",
    "            metrics.drop(columns=\"finetuning\", inplace=True)\n",
    "            id_vars.remove('finetuning')\n",
    "    if tok_position is not None:\n",
    "        metrics = metrics[metrics['tok_position'].isin(tok_position)]\n",
    "        if len(tok_position) == 1:\n",
    "            metrics.drop(columns=\"tok_position\", inplace=True)\n",
    "            id_vars.remove('tok_position')\n",
    "    if training_setup is not None:\n",
    "        metrics = metrics[metrics['training-setup'].isin(training_setup)]\n",
    "        if len(training_setup) == 1:\n",
    "            metrics.drop(columns=\"training-setup\", inplace=True)\n",
    "            id_vars.remove('training-setup')\n",
    "    if loss is not None:\n",
    "        metrics = metrics[metrics['loss'].isin(loss)]\n",
    "        if len(loss) == 1:\n",
    "            metrics.drop(columns=\"loss\", inplace=True)\n",
    "            id_vars.remove('loss')\n",
    "    if inference_config is not None:\n",
    "        metrics = metrics[metrics['inference_config'].isin(inference_config)]\n",
    "        if len(inference_config) == 1:\n",
    "            metrics.drop(columns=\"inference_config\", inplace=True)\n",
    "            id_vars.remove('inference_config')\n",
    "\n",
    "    if drop_i2t:\n",
    "        # remove columns containing i2t in the name of the second level of the multiindex\n",
    "        metrics = metrics.loc[:, ~metrics.columns.str.contains('i2t')]\n",
    "\n",
    "    # round to given decimal places\n",
    "    metrics = metrics.round(decimal_places)\n",
    "\n",
    "    metrics.set_index(id_vars, inplace=True)\n",
    "    metrics.sort_index(inplace=True)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename content of the table\n",
    "def rename_fn(v):\n",
    "    mapping = {'ContrastiveFixed': 'Triplet',\n",
    "               'InfoNCELoss': 'InfoNCE'}\n",
    "    if v in mapping:\n",
    "        return mapping[v]\n",
    "    return v\n",
    "\n",
    "def render_to_latex(metrics, rename_func=default_fields_dict, **latex_kwargs):\n",
    "    m = metrics.copy()\n",
    "     # make bold the best values\n",
    "\n",
    "    # Custom function to highlight the maximum value in each group\n",
    "    def highlight_best(data):\n",
    "        attr = 'font-weight: bold'\n",
    "        result = pd.DataFrame('', index=data.index, columns=data.columns)\n",
    "        for col in data.columns:\n",
    "            best_idx = data[col].idxmax()\n",
    "            # for idx in best_idx.values:\n",
    "            result.loc[best_idx, col] = attr\n",
    "        return result\n",
    "\n",
    "    styled_df = m.style.apply(highlight_best, axis=None)\n",
    "    ltex = styled_df.format(precision=2).to_latex(\n",
    "        **latex_kwargs\n",
    "    )\n",
    "    return ltex"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results - General retrieval (best contrastive sum checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{General Retrieval}\n",
      "\\begin{tabular}{llllccccc}\n",
      "\\toprule\n",
      " &  & t2i-r@1 & t2i-r@5 & t2i-r@10 & t2i-r@50 & contrastive_t2i_sum \\\\\n",
      "finetuning & inference_config &  &  &  &  &  \\\\\n",
      "\\midrule\n",
      "\\multirow[c]{6}{*}{disabled} & baseline & 12.10 & 56.20 & 69.10 & 92.20 & 229.60 \\\\\n",
      " & baseline_with_original_names & 26.20 & 58.20 & 70.10 & 91.80 & 246.30 \\\\\n",
      " & conf1 & 36.30 & 66.60 & 77.80 & 95.20 & 275.90 \\\\\n",
      " & conf1_static5 & 39.30 & 69.70 & \\bfseries 80.80 & 96.50 & 286.20 \\\\\n",
      " & conf3 & 36.40 & 65.00 & 75.80 & 94.40 & 271.50 \\\\\n",
      " & conf3_static5 & 38.00 & 67.10 & 78.30 & 95.50 & 278.90 \\\\\n",
      "\\cline{1-7}\n",
      "\\multirow[c]{6}{*}{shallow-vpt-5} & baseline & 12.40 & 57.90 & 70.60 & 93.20 & 234.10 \\\\\n",
      " & baseline_with_original_names & 27.90 & 61.70 & 72.90 & 93.00 & 255.50 \\\\\n",
      " & conf1 & 39.20 & 68.20 & 78.50 & 95.70 & 281.60 \\\\\n",
      " & conf1_static5 & \\bfseries 43.20 & \\bfseries 71.20 & 80.80 & \\bfseries 96.70 & \\bfseries 291.90 \\\\\n",
      " & conf3 & 37.50 & 66.10 & 76.30 & 94.30 & 274.10 \\\\\n",
      " & conf3_static5 & 39.90 & 68.60 & 78.10 & 95.00 & 281.60 \\\\\n",
      "\\cline{1-7}\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2840509/1616680159.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  metrics.drop(columns=\"model\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# collect all data\n",
    "ROOT = \"runs\"\n",
    "\n",
    "metrics = collect_all(ROOT, 'best-contrastive-sum')\n",
    "metrics_baselines = collect_all(ROOT, 'original_checkpoint')    # baseline model\n",
    "metrics_concat = pd.concat([metrics, metrics_baselines], axis=0, join='outer')\n",
    "\n",
    "metrics = summarize_metrics(\n",
    "    metrics_concat,\n",
    "    training_setup=[\"with_entities\", np.nan],\n",
    "    finetuning=[\"disabled\", \"shallow-vpt-5\"], #, np.nan],\n",
    "    model=[\"idclip\"],\n",
    "    inference_config=[\"conf1\", \"conf3\", \"conf1_static5\", \"conf3_static5\", \"baseline\", \"baseline_with_original_names\"],\n",
    "    tok_position=[\"tok_beginning_multi_prompts\"],\n",
    "    # tok_position=[\"tok_in_place_multi_prompts\", np.nan],\n",
    "    # tok_position_inference=[\"in_place\", None]\n",
    "    )\n",
    "\n",
    "# remove contrastive_sum columns\n",
    "metrics.drop(columns=\"contrastive_sum\", inplace=True)\n",
    "\n",
    "# remove data, translator, tok_position, training-setup, loss, lr, tok_position_inference from the multi index\n",
    "metrics.index = metrics.index.droplevel(['data', 'translator', 'training-setup', 'loss', 'lr'])\n",
    "\n",
    "# reorder columns to t2i-r@1 t2i-r@5 t2i-r@10 t2i-r@50 contrastive_t2i_sum\n",
    "metrics = metrics[[\"t2i-r@1\", \"t2i-r@5\", \"t2i-r@10\", \"t2i-r@50\", \"contrastive_t2i_sum\"]]\n",
    "\n",
    "# transform in percentage\n",
    "metrics = metrics * 100\n",
    "\n",
    "# # Select the top 2 rows with the highest \"contrastive_t2i_sum\" for each group of multiindex elements except \"inference_config\"\n",
    "# # a = metrics.groupby(['model', 'tok_position', 'finetuning'])['contrastive_t2i_sum'].apply(lambda x: x.nlargest(1).index)\n",
    "# # Reset the index to work with groupby and nlargest\n",
    "# metrics_reset = metrics.reset_index()\n",
    "# a = metrics_reset.groupby(['model', 'tok_position', 'finetuning'])['contrastive_t2i_sum'].nlargest(2)\n",
    "# # Select the top 2 rows with the highest \"contrastive_t2i_sum\" for each group of multiindex elements except \"inference_config\"\n",
    "# best_metrics = metrics_reset.loc[metrics_reset.groupby(['model', 'tok_position', 'finetuning'])['contrastive_t2i_sum'].nlargest(5).index.get_level_values(-1).tolist()]\n",
    "# # Set the index back to the original multiindex\n",
    "# best_metrics.set_index(['model', 'tok_position', 'finetuning', 'inference_config'], inplace=True)\n",
    "\n",
    "# best_metrics\n",
    "\n",
    "latex = render_to_latex(\n",
    "    metrics, \n",
    "    caption=\"General Retrieval\",\n",
    "    clines=\"skip-last;data\",\n",
    "    hrules=True,\n",
    "    column_format=\"llllccccc\",\n",
    "    convert_css=True\n",
    ")\n",
    "\n",
    "metrics.to_csv('metrics_training_with_tok_at_beginning.csv')\n",
    "\n",
    "print(latex)\n",
    "\n",
    "# metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results - Entities retrieval (best contrastive sum checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2840509/1616680159.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  metrics.drop(columns=\"model\", inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>entity-kmin-r@1</th>\n",
       "      <th>entity-kmin-r@5</th>\n",
       "      <th>entity-kmin-r@10</th>\n",
       "      <th>entity-kmin-r@50</th>\n",
       "      <th>entities_kmin_sum</th>\n",
       "      <th>mAP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>finetuning</th>\n",
       "      <th>inference_config</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">disabled</th>\n",
       "      <th>baseline_with_original_names</th>\n",
       "      <td>12.8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>17.5</td>\n",
       "      <td>44.8</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conf1</th>\n",
       "      <td>15.4</td>\n",
       "      <td>11.1</td>\n",
       "      <td>13.5</td>\n",
       "      <td>28.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conf1_2toks</th>\n",
       "      <td>16.5</td>\n",
       "      <td>10.8</td>\n",
       "      <td>13.1</td>\n",
       "      <td>28.1</td>\n",
       "      <td>68.5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conf1_3toks</th>\n",
       "      <td>18.2</td>\n",
       "      <td>10.8</td>\n",
       "      <td>12.8</td>\n",
       "      <td>27.4</td>\n",
       "      <td>69.2</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conf2</th>\n",
       "      <td>20.7</td>\n",
       "      <td>12.6</td>\n",
       "      <td>14.4</td>\n",
       "      <td>28.0</td>\n",
       "      <td>75.7</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conf3</th>\n",
       "      <td>20.4</td>\n",
       "      <td>11.8</td>\n",
       "      <td>13.9</td>\n",
       "      <td>28.0</td>\n",
       "      <td>74.1</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conf4</th>\n",
       "      <td>21.8</td>\n",
       "      <td>11.8</td>\n",
       "      <td>14.2</td>\n",
       "      <td>28.2</td>\n",
       "      <td>75.9</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conf5</th>\n",
       "      <td>21.8</td>\n",
       "      <td>11.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>75.1</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conf6</th>\n",
       "      <td>16.2</td>\n",
       "      <td>10.1</td>\n",
       "      <td>12.2</td>\n",
       "      <td>27.9</td>\n",
       "      <td>66.4</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">shallow-vpt-5</th>\n",
       "      <th>baseline_with_original_names</th>\n",
       "      <td>15.4</td>\n",
       "      <td>7.3</td>\n",
       "      <td>9.2</td>\n",
       "      <td>19.1</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conf1</th>\n",
       "      <td>21.2</td>\n",
       "      <td>11.5</td>\n",
       "      <td>14.2</td>\n",
       "      <td>31.9</td>\n",
       "      <td>78.9</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conf1_2toks</th>\n",
       "      <td>19.6</td>\n",
       "      <td>11.2</td>\n",
       "      <td>14.6</td>\n",
       "      <td>31.8</td>\n",
       "      <td>77.2</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conf1_3toks</th>\n",
       "      <td>19.0</td>\n",
       "      <td>11.8</td>\n",
       "      <td>14.8</td>\n",
       "      <td>31.4</td>\n",
       "      <td>77.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conf2</th>\n",
       "      <td>21.8</td>\n",
       "      <td>12.4</td>\n",
       "      <td>15.3</td>\n",
       "      <td>30.0</td>\n",
       "      <td>79.5</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conf3</th>\n",
       "      <td>22.6</td>\n",
       "      <td>11.6</td>\n",
       "      <td>14.6</td>\n",
       "      <td>29.7</td>\n",
       "      <td>78.6</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conf4</th>\n",
       "      <td>24.3</td>\n",
       "      <td>13.7</td>\n",
       "      <td>16.2</td>\n",
       "      <td>31.4</td>\n",
       "      <td>85.6</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conf5</th>\n",
       "      <td>22.9</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>31.3</td>\n",
       "      <td>82.8</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conf6</th>\n",
       "      <td>19.8</td>\n",
       "      <td>11.9</td>\n",
       "      <td>13.5</td>\n",
       "      <td>31.5</td>\n",
       "      <td>76.7</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            entity-kmin-r@1  entity-kmin-r@5  \\\n",
       "finetuning    inference_config                                                 \n",
       "disabled      baseline_with_original_names             12.8              6.0   \n",
       "              conf1                                    15.4             11.1   \n",
       "              conf1_2toks                              16.5             10.8   \n",
       "              conf1_3toks                              18.2             10.8   \n",
       "              conf2                                    20.7             12.6   \n",
       "              conf3                                    20.4             11.8   \n",
       "              conf4                                    21.8             11.8   \n",
       "              conf5                                    21.8             11.8   \n",
       "              conf6                                    16.2             10.1   \n",
       "shallow-vpt-5 baseline_with_original_names             15.4              7.3   \n",
       "              conf1                                    21.2             11.5   \n",
       "              conf1_2toks                              19.6             11.2   \n",
       "              conf1_3toks                              19.0             11.8   \n",
       "              conf2                                    21.8             12.4   \n",
       "              conf3                                    22.6             11.6   \n",
       "              conf4                                    24.3             13.7   \n",
       "              conf5                                    22.9             13.0   \n",
       "              conf6                                    19.8             11.9   \n",
       "\n",
       "                                            entity-kmin-r@10  \\\n",
       "finetuning    inference_config                                 \n",
       "disabled      baseline_with_original_names               8.4   \n",
       "              conf1                                     13.5   \n",
       "              conf1_2toks                               13.1   \n",
       "              conf1_3toks                               12.8   \n",
       "              conf2                                     14.4   \n",
       "              conf3                                     13.9   \n",
       "              conf4                                     14.2   \n",
       "              conf5                                     14.0   \n",
       "              conf6                                     12.2   \n",
       "shallow-vpt-5 baseline_with_original_names               9.2   \n",
       "              conf1                                     14.2   \n",
       "              conf1_2toks                               14.6   \n",
       "              conf1_3toks                               14.8   \n",
       "              conf2                                     15.3   \n",
       "              conf3                                     14.6   \n",
       "              conf4                                     16.2   \n",
       "              conf5                                     15.6   \n",
       "              conf6                                     13.5   \n",
       "\n",
       "                                            entity-kmin-r@50  \\\n",
       "finetuning    inference_config                                 \n",
       "disabled      baseline_with_original_names              17.5   \n",
       "              conf1                                     28.0   \n",
       "              conf1_2toks                               28.1   \n",
       "              conf1_3toks                               27.4   \n",
       "              conf2                                     28.0   \n",
       "              conf3                                     28.0   \n",
       "              conf4                                     28.2   \n",
       "              conf5                                     27.5   \n",
       "              conf6                                     27.9   \n",
       "shallow-vpt-5 baseline_with_original_names              19.1   \n",
       "              conf1                                     31.9   \n",
       "              conf1_2toks                               31.8   \n",
       "              conf1_3toks                               31.4   \n",
       "              conf2                                     30.0   \n",
       "              conf3                                     29.7   \n",
       "              conf4                                     31.4   \n",
       "              conf5                                     31.3   \n",
       "              conf6                                     31.5   \n",
       "\n",
       "                                            entities_kmin_sum  mAP  \n",
       "finetuning    inference_config                                      \n",
       "disabled      baseline_with_original_names               44.8  2.1  \n",
       "              conf1                                      68.0  3.1  \n",
       "              conf1_2toks                                68.5  3.0  \n",
       "              conf1_3toks                                69.2  3.1  \n",
       "              conf2                                      75.7  3.7  \n",
       "              conf3                                      74.1  3.6  \n",
       "              conf4                                      75.9  3.6  \n",
       "              conf5                                      75.1  3.6  \n",
       "              conf6                                      66.4  2.9  \n",
       "shallow-vpt-5 baseline_with_original_names               51.0  2.5  \n",
       "              conf1                                      78.9  3.7  \n",
       "              conf1_2toks                                77.2  3.5  \n",
       "              conf1_3toks                                77.0  3.5  \n",
       "              conf2                                      79.5  3.8  \n",
       "              conf3                                      78.6  3.8  \n",
       "              conf4                                      85.6  4.2  \n",
       "              conf5                                      82.8  4.0  \n",
       "              conf6                                      76.7  3.5  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collect all data\n",
    "ROOT = \"runs\"\n",
    "\n",
    "metrics = collect_all(ROOT, 'best-contrastive-sum', test_config='entities')\n",
    "metrics_baselines = collect_all(ROOT, 'original_checkpoint', test_config='entities')    # baseline model\n",
    "metrics_concat = pd.concat([metrics, metrics_baselines], axis=0, join='outer')\n",
    "\n",
    "metrics = summarize_metrics(\n",
    "    metrics_concat,\n",
    "    training_setup=[\"with_entities\", np.nan],\n",
    "    finetuning=[\"disabled\", \"shallow-vpt-5\"], #, np.nan],\n",
    "    model=[\"idclip\"],\n",
    "    # inference_config=[\"conf4\", \"baseline_with_original_names\"],\n",
    "    tok_position=[\"tok_beginning_multi_prompts\"],\n",
    "    # tok_position=[\"tok_in_place_multi_prompts\", np.nan],\n",
    "    # tok_position_inference=[\"in_place\", None]\n",
    "    )\n",
    "\n",
    "# remove all columns containing \"entity-r\"\n",
    "metrics = metrics.loc[:, ~metrics.columns.str.contains('entity-r')]\n",
    "metrics.drop(columns=\"entities_sum\", inplace=True)\n",
    "\n",
    "# remove data, translator, tok_position, training-setup, loss, lr, tok_position_inference from the multi index\n",
    "metrics.index = metrics.index.droplevel(['data', 'translator', 'training-setup', 'loss', 'lr'])\n",
    "\n",
    "# reorder columns to t2i-r@1 t2i-r@5 t2i-r@10 t2i-r@50 contrastive_t2i_sum\n",
    "metrics = metrics[[\"entity-kmin-r@1\", \"entity-kmin-r@5\", \"entity-kmin-r@10\", \"entity-kmin-r@50\", \"entities_kmin_sum\", \"mAP\"]]\n",
    "\n",
    "# transform in percentage\n",
    "metrics = metrics * 100\n",
    "\n",
    "latex = render_to_latex(\n",
    "    metrics, \n",
    "    caption=\"Entities Retrieval\",\n",
    "    clines=\"skip-last;data\",\n",
    "    hrules=True,\n",
    "    column_format=\"llllcccccc\",\n",
    "    convert_css=True\n",
    ")\n",
    "\n",
    "metrics\n",
    "# print(latex)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results - General retrieval (best entities sum checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all data\n",
    "ROOT = \"runs\"\n",
    "\n",
    "metrics = collect_all(ROOT, 'best-entities-sum')\n",
    "metrics_baselines = collect_all(ROOT, 'original_checkpoint')    # baseline model\n",
    "metrics_concat = pd.concat([metrics, metrics_baselines], axis=0, join='outer')\n",
    "\n",
    "metrics = summarize_metrics(\n",
    "    metrics_concat,\n",
    "    training_setup=[\"with_entities\", np.nan],\n",
    "    finetuning=[\"disabled\", \"shallow-vpt-5\", np.nan],\n",
    "    # tok_position=[\"tok_in_place_multi_prompts\", np.nan],\n",
    "    # tok_position_inference=[\"in_place\", None]\n",
    "    )\n",
    "\n",
    "# remove contrastive_sum columns\n",
    "metrics.drop(columns=\"contrastive_sum\", inplace=True)\n",
    "\n",
    "# remove data, translator, tok_position, training-setup, loss, lr, tok_position_inference from the multi index\n",
    "metrics.index = metrics.index.droplevel(['data', 'translator', 'training-setup', 'loss', 'lr'])\n",
    "\n",
    "# reorder columns to t2i-r@1 t2i-r@5 t2i-r@10 t2i-r@50 contrastive_t2i_sum\n",
    "metrics = metrics[[\"t2i-r@1\", \"t2i-r@5\", \"t2i-r@10\", \"t2i-r@50\", \"contrastive_t2i_sum\"]]\n",
    "\n",
    "# transform in percentage\n",
    "metrics = metrics * 100\n",
    "\n",
    "# latex = render_to_latex(\n",
    "#     metrics, \n",
    "#     caption=\"General Retrieval\",\n",
    "#     clines=\"skip-last;data\",\n",
    "#     hrules=True,\n",
    "#     column_format=\"llllccccc\",\n",
    "#     convert_css=True\n",
    "# )\n",
    "\n",
    "# print(latex)\n",
    "\n",
    "metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results - Entities retrieval (best entities sum checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all data\n",
    "ROOT = \"runs\"\n",
    "\n",
    "metrics = collect_all(ROOT, 'best-entities-sum', test_config='entities')\n",
    "metrics_baselines = collect_all(ROOT, 'original_checkpoint', test_config='entities')    # baseline model\n",
    "metrics_concat = pd.concat([metrics, metrics_baselines], axis=0, join='outer')\n",
    "\n",
    "metrics = summarize_metrics(\n",
    "    metrics_concat,\n",
    "    training_setup=[\"with_entities\", np.nan],\n",
    "    finetuning=[\"disabled\", \"shallow-vpt-5\", np.nan],\n",
    "    # tok_position=[\"tok_in_place_multi_prompts\", np.nan],\n",
    "    # tok_position_inference=[\"in_place\", None]\n",
    "    )\n",
    "\n",
    "# remove all columns containing \"entity-r\"\n",
    "metrics = metrics.loc[:, ~metrics.columns.str.contains('entity-r')]\n",
    "metrics.drop(columns=\"entities_sum\", inplace=True)\n",
    "\n",
    "# remove data, translator, tok_position, training-setup, loss, lr, tok_position_inference from the multi index\n",
    "metrics.index = metrics.index.droplevel(['data', 'translator', 'training-setup', 'loss', 'lr'])\n",
    "\n",
    "# reorder columns to t2i-r@1 t2i-r@5 t2i-r@10 t2i-r@50 contrastive_t2i_sum\n",
    "metrics = metrics[[\"entity-kmin-r@1\", \"entity-kmin-r@5\", \"entity-kmin-r@10\", \"entity-kmin-r@50\", \"entities_kmin_sum\", \"mAP\"]]\n",
    "\n",
    "# transform in percentage\n",
    "metrics = metrics * 100\n",
    "\n",
    "metrics\n",
    "\n",
    "# latex = render_to_latex(\n",
    "#     metrics, \n",
    "#     caption=\"Entities Retrieval\",\n",
    "#     clines=\"skip-last;data\",\n",
    "#     hrules=True,\n",
    "#     column_format=\"llllcccccc\",\n",
    "#     convert_css=True\n",
    "# )\n",
    "\n",
    "# print(latex)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idclip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "334a6e0c32e44839d9b4d52ebbe9bfa5e9e66772999102b43a3076c6d4d16d7f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
