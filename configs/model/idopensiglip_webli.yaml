defaults:
  - _self_
  - translator: mlp-1-layer
  - loss: info-nce

_target_: src.model.IdCLIP

clip_model: 
  _target_: open_clip.create_model_from_pretrained
  model_name: hf-hub:timm/ViT-SO400M-14-SigLIP-384
  shallow_visual_prompt_tokens: ${finetuning.shallow_visual_prompt_tokens}
  # shallow_text_prompt_tokens: ${finetuning.shallow_text_prompt_tokens}

tokenizer:
  _target_: open_clip.get_tokenizer
  model_name: hf-hub:timm/ViT-SO400M-14-SigLIP-384

train_visual_encoder: ${finetuning.train_visual_encoder}
train_text_encoder: ${finetuning.train_text_encoder}
encoders_lr: ${finetuning.encoders_lr}
training_setup: ${training_setup}

lr: 5e-5
